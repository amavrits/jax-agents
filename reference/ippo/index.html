
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://amavrits.github.io/jax-agents/reference/ippo/">
      
      
        <link rel="prev" href="../ippobase/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>IPPO - JAX Agents</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#jaxagents.ippo.IPPO" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="JAX Agents" class="md-header__button md-logo" aria-label="JAX Agents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            JAX Agents
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              IPPO
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/amavrits/jax-agents" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    amavrits/jax-agents
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../ppoagentbase/" class="md-tabs__link">
          
  
  
  Reference

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="JAX Agents" class="md-nav__button md-logo" aria-label="JAX Agents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    JAX Agents
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/amavrits/jax-agents" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    amavrits/jax-agents
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ppoagentbase/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PPOAgentBase
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ppoagent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PPOAgent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ippobase/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    IPPOBase
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    IPPO
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    IPPO
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO" class="md-nav__link">
    <span class="md-ellipsis">
      IPPO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._actor_loss" class="md-nav__link">
    <span class="md-ellipsis">
      _actor_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._actor_loss_input" class="md-nav__link">
    <span class="md-ellipsis">
      _actor_loss_input
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._critic_loss" class="md-nav__link">
    <span class="md-ellipsis">
      _critic_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._critic_loss_input" class="md-nav__link">
    <span class="md-ellipsis">
      _critic_loss_input
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._trajectory_advantages" class="md-nav__link">
    <span class="md-ellipsis">
      _trajectory_advantages
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._trajectory_returns" class="md-nav__link">
    <span class="md-ellipsis">
      _trajectory_returns
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO" class="md-nav__link">
    <span class="md-ellipsis">
      IPPO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._actor_loss" class="md-nav__link">
    <span class="md-ellipsis">
      _actor_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._actor_loss_input" class="md-nav__link">
    <span class="md-ellipsis">
      _actor_loss_input
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._critic_loss" class="md-nav__link">
    <span class="md-ellipsis">
      _critic_loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._critic_loss_input" class="md-nav__link">
    <span class="md-ellipsis">
      _critic_loss_input
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._trajectory_advantages" class="md-nav__link">
    <span class="md-ellipsis">
      _trajectory_advantages
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jaxagents.ippo.IPPO._trajectory_returns" class="md-nav__link">
    <span class="md-ellipsis">
      _trajectory_returns
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>IPPO</h1>

<div class="doc doc-object doc-class">



<a id="jaxagents.ippo.IPPO"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="jaxagents.ippo.IPPOBase" href="../ippobase/#jaxagents.ippo.IPPOBase">IPPOBase</a></code></p>


        <p>IPPO clip agent using the GAE (PPO2) for calculating the advantage. The actor loss function standardizes the
advantage.</p>







              <details class="quote">
                <summary>Source code in <code>jaxagents\ippo.py</code></summary>
                <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">IPPO</span><span class="p">(</span><span class="n">IPPOBase</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    IPPO clip agent using the GAE (PPO2) for calculating the advantage. The actor loss function standardizes the</span>
<span class="sd">    advantage.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_trajectory_returns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">traj</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the returns per episode step over a batch of trajectories.</span>
<span class="sd">        :param value: The values of the steps in the trajectory according to the critic (including the one of the last</span>
<span class="sd">        state). In the begining of the method, &#39;value&#39; is the value of the state in the next step in the trajectory</span>
<span class="sd">        (not the reverse iteration), and after calculation it is the value of the examined state in the examined step.</span>
<span class="sd">        :param traj: The trajectory batch.</span>
<span class="sd">        :return: An array of returns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rewards</span><span class="p">,</span> <span class="n">discounts</span><span class="p">,</span> <span class="n">next_state_values</span><span class="p">,</span> <span class="n">gae_lambda</span> <span class="o">=</span> <span class="n">traj</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="n">discounts</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gae_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">next_state_values</span> <span class="o">+</span> <span class="n">gae_lambda</span> <span class="o">*</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">value</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_trajectory_advantages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">advantage</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">traj</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the GAE per episode step over a batch of trajectories.</span>
<span class="sd">        :param advantage: The GAE advantages of the steps in the trajectory according to the critic (including the one</span>
<span class="sd">        of the last state). In the beginning of the method, &#39;advantage&#39; is the advantage of the state in the next step</span>
<span class="sd">        in the trajectory (not the reverse iteration), and after calculation it is the advantage of the examined state</span>
<span class="sd">        in each step.</span>
<span class="sd">        :param traj: The trajectory batch.</span>
<span class="sd">        :return: An array of returns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">next_state_values</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">gae_lambda</span> <span class="o">=</span> <span class="n">traj</span>
        <span class="n">d_t</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">next_state_values</span> <span class="o">-</span> <span class="n">values</span>  <span class="c1"># Temporal difference residual at time t</span>
        <span class="n">advantage</span> <span class="o">=</span> <span class="n">d_t</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">gae_lambda</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated</span><span class="p">)</span> <span class="o">*</span> <span class="n">advantage</span>
        <span class="k">return</span> <span class="n">advantage</span><span class="p">,</span> <span class="n">advantage</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_actor_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">training</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
            <span class="n">obs</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ObsType</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
            <span class="n">actions</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ActionType</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">log_prob_old</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
            <span class="n">advantage</span><span class="p">:</span> <span class="n">ReturnsType</span><span class="p">,</span>
            <span class="n">hyperparams</span><span class="p">:</span> <span class="n">HyperParameters</span>
    <span class="p">)</span><span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">],</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the actor loss. For the REINFORCE agent, the advantage function is the difference between the</span>
<span class="sd">        discounted returns and the value as estimated by the critic.</span>
<span class="sd">        :param training: The actor TrainState object.</span>
<span class="sd">        :param obs: The obs in the trajectory batch.</span>
<span class="sd">        :param actions: The actions in the trajectory batch.</span>
<span class="sd">        :param log_prob_old: Log-probabilities of the old policy collected over the trajectory batch.</span>
<span class="sd">        :param advantage: The GAE over the trajectory batch.</span>
<span class="sd">        :param hyperparams: The HyperParameters object used for training.</span>
<span class="sd">        :return: A tuple containing the actor loss and the KL divergence (for early checking stopping criterion).</span>
<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot; Standardize GAE, greatly improves behaviour&quot;&quot;&quot;</span>
        <span class="n">advantage</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantage</span> <span class="o">-</span> <span class="n">advantage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">advantage</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="n">log_prob_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob_vmap</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>
        <span class="n">log_policy_ratio</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">-</span> <span class="n">log_prob_old</span>
        <span class="n">policy_ratio</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_policy_ratio</span><span class="p">)</span>
        <span class="n">kl</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">log_policy_ratio</span><span class="p">)</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adopt simplified formulation of clipped policy ratio * advantage as explained in the note of:</span>
<span class="sd">        https://spinningup.openai.com/en/latest/algorithms/ppo.html#id2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">clip</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">advantage</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">eps_clip</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">eps_clip</span><span class="p">)</span>
        <span class="n">advantage_clip</span> <span class="o">=</span> <span class="n">advantage</span> <span class="o">*</span> <span class="n">clip</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Actual clip calculation - not used but left here for comparison to simplified version&quot;&quot;&quot;</span>
        <span class="c1"># advantage_clip = jnp.clip(policy_ratio, 1 - hyperparams.eps_clip, 1 + hyperparams.eps_clip) * advantage</span>

        <span class="n">loss_actor</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">policy_ratio</span> <span class="o">*</span> <span class="n">advantage</span><span class="p">,</span> <span class="n">advantage_clip</span><span class="p">)</span>

        <span class="n">entropy_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_entropy</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">entropy_vmap</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>

        <span class="n">total_loss_actor</span> <span class="o">=</span> <span class="n">loss_actor</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">ent_coeff</span> <span class="o">*</span> <span class="n">entropy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot; Negative loss, because we want ascent but &#39;apply_gradients&#39; applies descent &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">total_loss_actor</span><span class="p">,</span> <span class="n">kl</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_critic_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">training</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
            <span class="n">obs</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ObsType</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
            <span class="n">targets</span><span class="p">:</span> <span class="n">ReturnsType</span><span class="p">,</span>
            <span class="n">hyperparams</span><span class="p">:</span> <span class="n">HyperParameters</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the critic loss.</span>
<span class="sd">        :param training: The critic TrainState object.</span>
<span class="sd">        :param obs: The obs in the trajectory batch.</span>
<span class="sd">        :param targets: The targets over the trajectory batch for training the critic.</span>
<span class="sd">        :param hyperparams: The HyperParameters object used for training.</span>
<span class="sd">        :return: The critic loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">value_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value_vmap</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="n">value</span> <span class="o">-</span> <span class="n">targets</span>
        <span class="n">value_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">critic_total_loss</span> <span class="o">=</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">vf_coeff</span> <span class="o">*</span> <span class="n">value_loss</span>

        <span class="k">return</span> <span class="n">critic_total_loss</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_actor_loss_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">update_runner</span><span class="p">:</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActorLossInputType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepares the input required by the actor loss function. For the PPO agent, this entails the:</span>
<span class="sd">        - the actions collected over the trajectory batch.</span>
<span class="sd">        - the log-probability of the actions collected over the trajectory batch.</span>
<span class="sd">        - the returns over the trajectory batch.</span>
<span class="sd">        - the values over the trajectory batch as evaluated by the critic.</span>
<span class="sd">        - the training hyperparameters.</span>
<span class="sd">        The input is reshaped so that it is split into minibatches.</span>
<span class="sd">        :param update_runner: The Runner object used in training.</span>
<span class="sd">        :param traj_batch: The batch of trajectories.</span>
<span class="sd">        :return: A tuple of input to the actor loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Shuffle the trajectory batch to collect minibatches.</span>
        <span class="c1"># Poor practice in using the random key, which however doesn&#39;t influence the training, since all trajectories in</span>
        <span class="c1"># the batch are used per epoch.</span>
        <span class="n">minibatch_idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,)</span>
        <span class="p">)</span>

        <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">minibatch_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">traj_batch</span><span class="p">)</span>
        <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">traj_minibatch</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">action</span><span class="p">,</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">log_prob</span><span class="p">,</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">advantage</span><span class="p">,</span>
            <span class="n">update_runner</span><span class="o">.</span><span class="n">hyperparams</span>
        <span class="p">)</span>

    <span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_critic_loss_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">update_runner</span><span class="p">:</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CriticLossInputType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepares the input required by the critic loss function. For the PPO agent, this entails the:</span>
<span class="sd">        - the states collected over the trajectory batch.</span>
<span class="sd">        - the targets (returns = GAE + next_value) over the trajectory batch.</span>
<span class="sd">        - the training hyperparameters.</span>
<span class="sd">        The input is reshaped so that it is split into minibatches.</span>
<span class="sd">        :param update_runner: The Runner object used in training.</span>
<span class="sd">        :param traj_batch: The batch of trajectories.</span>
<span class="sd">        :return: A tuple of input to the critic loss function.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Shuffle the trajectory batch to collect minibatches.</span>
        <span class="c1"># Poor practice in using the random key, which however doesn&#39;t influence the training, since all trajectories in</span>
        <span class="c1"># the batch are used per epoch.</span>
        <span class="n">minibatch_idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,)</span>
        <span class="p">)</span>

        <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">minibatch_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">traj_batch</span><span class="p">)</span>
        <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">traj_minibatch</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
            <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">advantage</span> <span class="o">+</span> <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">update_runner</span><span class="o">.</span><span class="n">hyperparams</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._actor_loss" class="doc doc-heading">
            <code class=" language-python"><span class="n">_actor_loss</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">log_prob_old</span><span class="p">,</span> <span class="n">advantage</span><span class="p">,</span> <span class="n">hyperparams</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._actor_loss" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Calculates the actor loss. For the REINFORCE agent, the advantage function is the difference between the
discounted returns and the value as estimated by the critic.
:param training: The actor TrainState object.
:param obs: The obs in the trajectory batch.
:param actions: The actions in the trajectory batch.
:param log_prob_old: Log-probabilities of the old policy collected over the trajectory batch.
:param advantage: The GAE over the trajectory batch.
:param hyperparams: The HyperParameters object used for training.
:return: A tuple containing the actor loss and the KL divergence (for early checking stopping criterion).</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_actor_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">training</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
        <span class="n">obs</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ObsType</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
        <span class="n">actions</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ActionType</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
        <span class="n">log_prob_old</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
        <span class="n">advantage</span><span class="p">:</span> <span class="n">ReturnsType</span><span class="p">,</span>
        <span class="n">hyperparams</span><span class="p">:</span> <span class="n">HyperParameters</span>
<span class="p">)</span><span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">],</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the actor loss. For the REINFORCE agent, the advantage function is the difference between the</span>
<span class="sd">    discounted returns and the value as estimated by the critic.</span>
<span class="sd">    :param training: The actor TrainState object.</span>
<span class="sd">    :param obs: The obs in the trajectory batch.</span>
<span class="sd">    :param actions: The actions in the trajectory batch.</span>
<span class="sd">    :param log_prob_old: Log-probabilities of the old policy collected over the trajectory batch.</span>
<span class="sd">    :param advantage: The GAE over the trajectory batch.</span>
<span class="sd">    :param hyperparams: The HyperParameters object used for training.</span>
<span class="sd">    :return: A tuple containing the actor loss and the KL divergence (for early checking stopping criterion).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot; Standardize GAE, greatly improves behaviour&quot;&quot;&quot;</span>
    <span class="n">advantage</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantage</span> <span class="o">-</span> <span class="n">advantage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">advantage</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

    <span class="n">log_prob_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_prob</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob_vmap</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>
    <span class="n">log_policy_ratio</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">-</span> <span class="n">log_prob_old</span>
    <span class="n">policy_ratio</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_policy_ratio</span><span class="p">)</span>
    <span class="n">kl</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">log_policy_ratio</span><span class="p">)</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adopt simplified formulation of clipped policy ratio * advantage as explained in the note of:</span>
<span class="sd">    https://spinningup.openai.com/en/latest/algorithms/ppo.html#id2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clip</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">advantage</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">eps_clip</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">eps_clip</span><span class="p">)</span>
    <span class="n">advantage_clip</span> <span class="o">=</span> <span class="n">advantage</span> <span class="o">*</span> <span class="n">clip</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;Actual clip calculation - not used but left here for comparison to simplified version&quot;&quot;&quot;</span>
    <span class="c1"># advantage_clip = jnp.clip(policy_ratio, 1 - hyperparams.eps_clip, 1 + hyperparams.eps_clip) * advantage</span>

    <span class="n">loss_actor</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">policy_ratio</span> <span class="o">*</span> <span class="n">advantage</span><span class="p">,</span> <span class="n">advantage_clip</span><span class="p">)</span>

    <span class="n">entropy_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_entropy</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="n">entropy_vmap</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>

    <span class="n">total_loss_actor</span> <span class="o">=</span> <span class="n">loss_actor</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">ent_coeff</span> <span class="o">*</span> <span class="n">entropy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot; Negative loss, because we want ascent but &#39;apply_gradients&#39; applies descent &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">total_loss_actor</span><span class="p">,</span> <span class="n">kl</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._actor_loss_input" class="doc doc-heading">
            <code class=" language-python"><span class="n">_actor_loss_input</span><span class="p">(</span><span class="n">update_runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._actor_loss_input" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Prepares the input required by the actor loss function. For the PPO agent, this entails the:
- the actions collected over the trajectory batch.
- the log-probability of the actions collected over the trajectory batch.
- the returns over the trajectory batch.
- the values over the trajectory batch as evaluated by the critic.
- the training hyperparameters.
The input is reshaped so that it is split into minibatches.
:param update_runner: The Runner object used in training.
:param traj_batch: The batch of trajectories.
:return: A tuple of input to the actor loss function.</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_actor_loss_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">update_runner</span><span class="p">:</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActorLossInputType</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prepares the input required by the actor loss function. For the PPO agent, this entails the:</span>
<span class="sd">    - the actions collected over the trajectory batch.</span>
<span class="sd">    - the log-probability of the actions collected over the trajectory batch.</span>
<span class="sd">    - the returns over the trajectory batch.</span>
<span class="sd">    - the values over the trajectory batch as evaluated by the critic.</span>
<span class="sd">    - the training hyperparameters.</span>
<span class="sd">    The input is reshaped so that it is split into minibatches.</span>
<span class="sd">    :param update_runner: The Runner object used in training.</span>
<span class="sd">    :param traj_batch: The batch of trajectories.</span>
<span class="sd">    :return: A tuple of input to the actor loss function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Shuffle the trajectory batch to collect minibatches.</span>
    <span class="c1"># Poor practice in using the random key, which however doesn&#39;t influence the training, since all trajectories in</span>
    <span class="c1"># the batch are used per epoch.</span>
    <span class="n">minibatch_idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span>
        <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,)</span>
    <span class="p">)</span>

    <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">minibatch_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">traj_batch</span><span class="p">)</span>
    <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">traj_minibatch</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">action</span><span class="p">,</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">log_prob</span><span class="p">,</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">advantage</span><span class="p">,</span>
        <span class="n">update_runner</span><span class="o">.</span><span class="n">hyperparams</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._critic_loss" class="doc doc-heading">
            <code class=" language-python"><span class="n">_critic_loss</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hyperparams</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._critic_loss" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Calculates the critic loss.
:param training: The critic TrainState object.
:param obs: The obs in the trajectory batch.
:param targets: The targets over the trajectory batch for training the critic.
:param hyperparams: The HyperParameters object used for training.
:return: The critic loss.</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_critic_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">training</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
        <span class="n">obs</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">ObsType</span><span class="p">,</span> <span class="s2">&quot;n_rollout batch_size&quot;</span><span class="p">],</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">ReturnsType</span><span class="p">,</span>
        <span class="n">hyperparams</span><span class="p">:</span> <span class="n">HyperParameters</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the critic loss.</span>
<span class="sd">    :param training: The critic TrainState object.</span>
<span class="sd">    :param obs: The obs in the trajectory batch.</span>
<span class="sd">    :param targets: The targets over the trajectory batch for training the critic.</span>
<span class="sd">    :param hyperparams: The HyperParameters object used for training.</span>
<span class="sd">    :return: The critic loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">value_vmap</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">value_vmap</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">value</span> <span class="o">-</span> <span class="n">targets</span>
    <span class="n">value_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">critic_total_loss</span> <span class="o">=</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">vf_coeff</span> <span class="o">*</span> <span class="n">value_loss</span>

    <span class="k">return</span> <span class="n">critic_total_loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._critic_loss_input" class="doc doc-heading">
            <code class=" language-python"><span class="n">_critic_loss_input</span><span class="p">(</span><span class="n">update_runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._critic_loss_input" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Prepares the input required by the critic loss function. For the PPO agent, this entails the:
- the states collected over the trajectory batch.
- the targets (returns = GAE + next_value) over the trajectory batch.
- the training hyperparameters.
The input is reshaped so that it is split into minibatches.
:param update_runner: The Runner object used in training.
:param traj_batch: The batch of trajectories.
:return: A tuple of input to the critic loss function.</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_critic_loss_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">update_runner</span><span class="p">:</span> <span class="n">Runner</span><span class="p">,</span> <span class="n">traj_batch</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CriticLossInputType</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prepares the input required by the critic loss function. For the PPO agent, this entails the:</span>
<span class="sd">    - the states collected over the trajectory batch.</span>
<span class="sd">    - the targets (returns = GAE + next_value) over the trajectory batch.</span>
<span class="sd">    - the training hyperparameters.</span>
<span class="sd">    The input is reshaped so that it is split into minibatches.</span>
<span class="sd">    :param update_runner: The Runner object used in training.</span>
<span class="sd">    :param traj_batch: The batch of trajectories.</span>
<span class="sd">    :return: A tuple of input to the critic loss function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Shuffle the trajectory batch to collect minibatches.</span>
    <span class="c1"># Poor practice in using the random key, which however doesn&#39;t influence the training, since all trajectories in</span>
    <span class="c1"># the batch are used per epoch.</span>
    <span class="n">minibatch_idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span>
        <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,)</span>
    <span class="p">)</span>

    <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">minibatch_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">traj_batch</span><span class="p">)</span>
    <span class="n">traj_minibatch</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">traj_minibatch</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
        <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">advantage</span> <span class="o">+</span> <span class="n">traj_minibatch</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="n">update_runner</span><span class="o">.</span><span class="n">hyperparams</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._trajectory_advantages" class="doc doc-heading">
            <code class=" language-python"><span class="n">_trajectory_advantages</span><span class="p">(</span><span class="n">advantage</span><span class="p">,</span> <span class="n">traj</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._trajectory_advantages" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Calculates the GAE per episode step over a batch of trajectories.
:param advantage: The GAE advantages of the steps in the trajectory according to the critic (including the one
of the last state). In the beginning of the method, 'advantage' is the advantage of the state in the next step
in the trajectory (not the reverse iteration), and after calculation it is the advantage of the examined state
in each step.
:param traj: The trajectory batch.
:return: An array of returns.</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_trajectory_advantages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">advantage</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">traj</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the GAE per episode step over a batch of trajectories.</span>
<span class="sd">    :param advantage: The GAE advantages of the steps in the trajectory according to the critic (including the one</span>
<span class="sd">    of the last state). In the beginning of the method, &#39;advantage&#39; is the advantage of the state in the next step</span>
<span class="sd">    in the trajectory (not the reverse iteration), and after calculation it is the advantage of the examined state</span>
<span class="sd">    in each step.</span>
<span class="sd">    :param traj: The trajectory batch.</span>
<span class="sd">    :return: An array of returns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">next_state_values</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">gae_lambda</span> <span class="o">=</span> <span class="n">traj</span>
    <span class="n">d_t</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">next_state_values</span> <span class="o">-</span> <span class="n">values</span>  <span class="c1"># Temporal difference residual at time t</span>
    <span class="n">advantage</span> <span class="o">=</span> <span class="n">d_t</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">gae_lambda</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated</span><span class="p">)</span> <span class="o">*</span> <span class="n">advantage</span>
    <span class="k">return</span> <span class="n">advantage</span><span class="p">,</span> <span class="n">advantage</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="jaxagents.ippo.IPPO._trajectory_returns" class="doc doc-heading">
            <code class=" language-python"><span class="n">_trajectory_returns</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">traj</span><span class="p">)</span></code>

<a href="#jaxagents.ippo.IPPO._trajectory_returns" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Calculates the returns per episode step over a batch of trajectories.
:param value: The values of the steps in the trajectory according to the critic (including the one of the last
state). In the begining of the method, 'value' is the value of the state in the next step in the trajectory
(not the reverse iteration), and after calculation it is the value of the examined state in the examined step.
:param traj: The trajectory batch.
:return: An array of returns.</p>


            <details class="quote">
              <summary>Source code in <code>jaxagents\ippo.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_trajectory_returns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Array</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">traj</span><span class="p">:</span> <span class="n">Transition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the returns per episode step over a batch of trajectories.</span>
<span class="sd">    :param value: The values of the steps in the trajectory according to the critic (including the one of the last</span>
<span class="sd">    state). In the begining of the method, &#39;value&#39; is the value of the state in the next step in the trajectory</span>
<span class="sd">    (not the reverse iteration), and after calculation it is the value of the examined state in the examined step.</span>
<span class="sd">    :param traj: The trajectory batch.</span>
<span class="sd">    :return: An array of returns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rewards</span><span class="p">,</span> <span class="n">discounts</span><span class="p">,</span> <span class="n">next_state_values</span><span class="p">,</span> <span class="n">gae_lambda</span> <span class="o">=</span> <span class="n">traj</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="n">discounts</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gae_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">next_state_values</span> <span class="o">+</span> <span class="n">gae_lambda</span> <span class="o">*</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">value</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/amavrits/jax-agents" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tabs", "search.highlight", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>